{
    "docs": [
        {
            "location": "/", 
            "text": "Documentation for the Goal-Oriented Chatbots\n\n\nIn these pages, the documentation of the library for developing goal-oriented chatbots is provided. The goal-oriented chatbots are closed domain chatbots with a predetermined intent to help users complete a task. For example, the task could be a flight booking or restaurant reservation.\n\n\nThis library is modeling the goal-oriented chatbots as a Partially Observable Markov Decision Process (POMDP) using the Reinforcement Learning (RL) set of algorithms. Therefore, there is an agent, acting in a dialogue environment and learning the dialogue policy by receiving reward signals.\n\n\nSince reinforcement learners require an environment to interact, conventional dialogue corpora cannot be used directly. For this reason, we need a simulator which will simulate the user behavior. Using this approach, on one side we have a simulated user with a predetermined goal to acheve, using the agent which is not aware of the user goal.\n\n\nBoth of them are generating actions, the simulated user is generating the action based on its goal, while the agent is generating the action based on its beliefs learned from the training so far.\n\n\nThe notion of user goal\n\n\nAs we mentioned above, in this kind of chatbot scenario, the users are having goal. Therefore, we need to provide a formal goal definition. When the users are having goal, on one side they know some piece of information and on the other side they are searching for some other piece of information that they would like to know.\n\n\nThese chunks of information, which are the point of interest, are called \nslots\n, such that the slot is having a \nkey name\n (some general term) and a \nvalue\n, i.e. they act as a key-value pairs. Following the user's nature, we define two types of slots: \n inform \n and \n request \n slots. The \n inform \n slots have value, while the \n request \n slots do not have value. The slots are domain dependent and differ from domain to domain. Therefore, they are specified in the input, as it is explained in the \nInput\n section.\n\n\nFor example, in a restaurant booking scenario, the user might know the type of cuisine, for example \nIndian\n, but she might not know any restaurant serving that kind of food. Therefore, we will have an \n inform \n slot named \ncuisine\n with a value \nIndian\n and one \n request \n slot named \nrestaurant\n. The chatbot should give an answer to that.\n\n\nIn this system, the user goal is encoded in the following semantic structure:\n\n\n \n{\n \n\n\n \n\"request_slots\" : { ... }\n, \n\n\n \n\"inform_slots\" : { ... }\n \n\n\n \n}\n\n\nUser and agent actions\n\n\nAs we already mentioned, both, the agent and the user are taking actions. The user action is derived from its goal, the agent action is derived from its policy. In order to establish a convention in the system, the actions are all having same format. It is including the following info: type of the action, inform slots, request slots and the natural language representation.\n\n\nThe type of action, or the dialogue act (intent) is describing the nature of the action. Since, for now there in only a rule based user simulator, the system supports 11 dialogue acts, which are the following: \n\n\n\n\nrequest\n\n\ninform\n\n\nconfirm_question\n\n\nconfirm_answer\n\n\ngreeting\n\n\nclosing\n\n\nmultiple_choice\n\n\nthanks\n\n\nwelcome\n\n\ndeny\n\n\nnot_sure\n\n\n\n\nThe inform and request slots are same as in the goal, while the natural language representation is a sencente corresponding to the the action.", 
            "title": "Home"
        }, 
        {
            "location": "/#documentation-for-the-goal-oriented-chatbots", 
            "text": "In these pages, the documentation of the library for developing goal-oriented chatbots is provided. The goal-oriented chatbots are closed domain chatbots with a predetermined intent to help users complete a task. For example, the task could be a flight booking or restaurant reservation.  This library is modeling the goal-oriented chatbots as a Partially Observable Markov Decision Process (POMDP) using the Reinforcement Learning (RL) set of algorithms. Therefore, there is an agent, acting in a dialogue environment and learning the dialogue policy by receiving reward signals.  Since reinforcement learners require an environment to interact, conventional dialogue corpora cannot be used directly. For this reason, we need a simulator which will simulate the user behavior. Using this approach, on one side we have a simulated user with a predetermined goal to acheve, using the agent which is not aware of the user goal.  Both of them are generating actions, the simulated user is generating the action based on its goal, while the agent is generating the action based on its beliefs learned from the training so far.", 
            "title": "Documentation for the Goal-Oriented Chatbots"
        }, 
        {
            "location": "/#the-notion-of-user-goal", 
            "text": "As we mentioned above, in this kind of chatbot scenario, the users are having goal. Therefore, we need to provide a formal goal definition. When the users are having goal, on one side they know some piece of information and on the other side they are searching for some other piece of information that they would like to know.  These chunks of information, which are the point of interest, are called  slots , such that the slot is having a  key name  (some general term) and a  value , i.e. they act as a key-value pairs. Following the user's nature, we define two types of slots:   inform   and   request   slots. The   inform   slots have value, while the   request   slots do not have value. The slots are domain dependent and differ from domain to domain. Therefore, they are specified in the input, as it is explained in the  Input  section.  For example, in a restaurant booking scenario, the user might know the type of cuisine, for example  Indian , but she might not know any restaurant serving that kind of food. Therefore, we will have an   inform   slot named  cuisine  with a value  Indian  and one   request   slot named  restaurant . The chatbot should give an answer to that.  In this system, the user goal is encoded in the following semantic structure:    {      \"request_slots\" : { ... } ,     \"inform_slots\" : { ... }      }", 
            "title": "The notion of user goal"
        }, 
        {
            "location": "/#user-and-agent-actions", 
            "text": "As we already mentioned, both, the agent and the user are taking actions. The user action is derived from its goal, the agent action is derived from its policy. In order to establish a convention in the system, the actions are all having same format. It is including the following info: type of the action, inform slots, request slots and the natural language representation.  The type of action, or the dialogue act (intent) is describing the nature of the action. Since, for now there in only a rule based user simulator, the system supports 11 dialogue acts, which are the following:    request  inform  confirm_question  confirm_answer  greeting  closing  multiple_choice  thanks  welcome  deny  not_sure   The inform and request slots are same as in the goal, while the natural language representation is a sencente corresponding to the the action.", 
            "title": "User and agent actions"
        }, 
        {
            "location": "/input/", 
            "text": "Input\n\n\nIn this section we will describe the input expected by the system. It includes the following:\n\n\n\n\nslot set\n: the set of all slots of interest in the given domain\n\n\nuser goals set\n: the set of all user goals\n\n\nagent actions set\n : the set of all agent actions\n\n\ninitial inform slots\n:\n\n\ninitial request slots\n:\n\n\n\n\nStatic parts:\n\n\nThe user and the agent actions are always having the same format:", 
            "title": "Input"
        }, 
        {
            "location": "/input/#input", 
            "text": "In this section we will describe the input expected by the system. It includes the following:   slot set : the set of all slots of interest in the given domain  user goals set : the set of all user goals  agent actions set  : the set of all agent actions  initial inform slots :  initial request slots :", 
            "title": "Input"
        }, 
        {
            "location": "/input/#static-parts", 
            "text": "The user and the agent actions are always having the same format:", 
            "title": "Static parts:"
        }, 
        {
            "location": "/sources/dm/overview/", 
            "text": "[source]\n\n\nGODialogSys\n\n\ncore.dm.dialogue_system.GODialogSys(act_set=None, slot_set=None, agt_feasible_actions=None, params=None)\n\n\n\n\nThe GO Dialogue System mediates the interaction between the environment and the agent.\n\n\nClass members: \n\n\n\n\n agent \n: the type of conversational agent. Default is None (temporarily).\n\n\n environment \n: the environment with which the agent and user interact. Default is None (temporarily).\n\n\n\n\n act_set \n: static set of all dialogue acts (intents) used in the dialogue. This set includes the following:\n\n\n\n\n request \n: the dialogue turn is requesting a value for some slots\n\n\n inform \n: the dialogue turn is providing values (constraints) for some values\n\n\n confirm_question \n:\n\n\n confirm_answer \n: \n\n\n greeting \n: the turn does not provide any info else than a greeting\n\n\n closing \n: the turn\n\n\n multiple_choice \n: when the turn includes\n\n\n thanks \n: the turn does not provide any info else than a thanks words\n\n\n welcome \n: the turn does not provide any info else than a welcoming words\n\n\n deny \n:\n\n\n not_sure \n:\n\n\n slot_set \n: the set of all slots used in the dialogue.\n\n\n kb_path \n: path to any knowledge base\n\n\n agt_feasible_actions \n: list of templates described as dictionaries, corresponding to each action the agent might take\n        (dict to be specified)\n\n\n max_nb_turns \n: the maximal number of dialogue turns", 
            "title": "Overview"
        }, 
        {
            "location": "/sources/dm/overview/#godialogsys", 
            "text": "core.dm.dialogue_system.GODialogSys(act_set=None, slot_set=None, agt_feasible_actions=None, params=None)  The GO Dialogue System mediates the interaction between the environment and the agent.  Class members:     agent  : the type of conversational agent. Default is None (temporarily).   environment  : the environment with which the agent and user interact. Default is None (temporarily).    act_set  : static set of all dialogue acts (intents) used in the dialogue. This set includes the following:    request  : the dialogue turn is requesting a value for some slots   inform  : the dialogue turn is providing values (constraints) for some values   confirm_question  :   confirm_answer  :    greeting  : the turn does not provide any info else than a greeting   closing  : the turn   multiple_choice  : when the turn includes   thanks  : the turn does not provide any info else than a thanks words   welcome  : the turn does not provide any info else than a welcoming words   deny  :   not_sure  :   slot_set  : the set of all slots used in the dialogue.   kb_path  : path to any knowledge base   agt_feasible_actions  : list of templates described as dictionaries, corresponding to each action the agent might take\n        (dict to be specified)   max_nb_turns  : the maximal number of dialogue turns", 
            "title": "GODialogSys"
        }, 
        {
            "location": "/sources/dm/dialogue_sys/", 
            "text": "[source]\n\n\nGODialogSys\n\n\ncore.dm.dialogue_system.GODialogSys(act_set=None, slot_set=None, agt_feasible_actions=None, params=None)\n\n\n\n\nThe GO Dialogue System mediates the interaction between the environment and the agent.\n\n\nClass members: \n\n\n\n\n agent \n: the type of conversational agent. Default is None (temporarily).\n\n\n environment \n: the environment with which the agent and user interact. Default is None (temporarily).\n\n\n\n\n act_set \n: static set of all dialogue acts (intents) used in the dialogue. This set includes the following:\n\n\n\n\n request \n: the dialogue turn is requesting a value for some slots\n\n\n inform \n: the dialogue turn is providing values (constraints) for some values\n\n\n confirm_question \n:\n\n\n confirm_answer \n: \n\n\n greeting \n: the turn does not provide any info else than a greeting\n\n\n closing \n: the turn\n\n\n multiple_choice \n: when the turn includes\n\n\n thanks \n: the turn does not provide any info else than a thanks words\n\n\n welcome \n: the turn does not provide any info else than a welcoming words\n\n\n deny \n:\n\n\n not_sure \n:\n\n\n slot_set \n: the set of all slots used in the dialogue.\n\n\n kb_path \n: path to any knowledge base\n\n\n agt_feasible_actions \n: list of templates described as dictionaries, corresponding to each action the agent might take\n        (dict to be specified)\n\n\n max_nb_turns \n: the maximal number of dialogue turns\n\n\n\n\n\n\n\n\n\n\n[source]\n\n\ninitialize\n\n\ninitialize(self)\n\n\n\n\nMethod for initializing the dialogue.\n\n\n:return:", 
            "title": "GODialogSys"
        }, 
        {
            "location": "/sources/dm/dialogue_sys/#godialogsys", 
            "text": "core.dm.dialogue_system.GODialogSys(act_set=None, slot_set=None, agt_feasible_actions=None, params=None)  The GO Dialogue System mediates the interaction between the environment and the agent.  Class members:     agent  : the type of conversational agent. Default is None (temporarily).   environment  : the environment with which the agent and user interact. Default is None (temporarily).    act_set  : static set of all dialogue acts (intents) used in the dialogue. This set includes the following:    request  : the dialogue turn is requesting a value for some slots   inform  : the dialogue turn is providing values (constraints) for some values   confirm_question  :   confirm_answer  :    greeting  : the turn does not provide any info else than a greeting   closing  : the turn   multiple_choice  : when the turn includes   thanks  : the turn does not provide any info else than a thanks words   welcome  : the turn does not provide any info else than a welcoming words   deny  :   not_sure  :   slot_set  : the set of all slots used in the dialogue.   kb_path  : path to any knowledge base   agt_feasible_actions  : list of templates described as dictionaries, corresponding to each action the agent might take\n        (dict to be specified)   max_nb_turns  : the maximal number of dialogue turns      [source]", 
            "title": "GODialogSys"
        }, 
        {
            "location": "/sources/dm/dialogue_sys/#initialize", 
            "text": "initialize(self)  Method for initializing the dialogue.  :return:", 
            "title": "initialize"
        }, 
        {
            "location": "/sources/agents/overview/", 
            "text": "[source]\n\n\nGODQNAgent\n\n\ncore.agent.agents.GODQNAgent()\n\n\n\n\nClass for the Goal-Oriented agents with a DQN-based policy learning.\n\n\nThis class is extending the class AbstractDQNAgent from keras-rl framework.\nThis type of DQN agent should learn the policies of a dialogue in a given environment.\n\n\nOne agent action is represented as a dictionary having the exact same structure as the user action, which is:\n\n\n\n\n diaact \n: the act (intent) of the action\n\n\n inform_slots \n: the set of informed slots\n\n\n request_slots \n: the set of request slots\n\n\n nl \n: the natural language representation of the agent action\n\n\n\n\nThe following methods are implemented:\n\n\n\n\nforward\n\n\nbackward\n\n\ncompile\n\n\nload_weights\n\n\nsave_weights\n\n\nlayers\n\n\n\n\nClass members:\n\n\nFrom  \nAgent\n class:\n\n\n\n\n processor \n (\nProcessor\n instance): glue between the environment and the agent\n\n\n\n\nFrom  \nAbstractDQNAgent\n class:\n\n\n\n\n nb_actions \n: the number of all possible actions\n\n\n memory \n (\nMemory\n instance): the type of buffer the agent will use. For example: SequentialMemory\n\n\n gamma \n: the discount reward factor. Default is 0.99, the agent remembers everything\n\n\n batch_size \n: the number of memories to replay in one training epoch. Default is 32\n\n\n nb_steps_warmup \n: the number of steps needed to warm up and fill the memory replay buffer. Default is 1000\n\n\n train_interval \n: no idea\n\n\n memory_interval \n: no idea\n\n\n target_model_update \n: after how many steps, the target DQN gets updated. Default is 10 000\n\n\n delta_range \n: no idea. Default is None. This variable is deprecated\n\n\n delta_clip \n: no idea. Default is Inf\n\n\n custom_model_objects \n: no idea\n\n\n\n\nFrom \nDQNAgent\n class:\n\n\n\n\n policy \n (\nPolicy\n instance): The policy that the agent follows. Default is None\n\n\n test_policy \n (\nPolicy\n instance): The policy that the agent follows during testing. Default is None\n\n\n enable_double_dqn \n: To enable the Double DQN technique. By default is on\n\n\n enable_dueling_network \n: To enble the Dueling DQN technique. Be default is off\n\n\n dueling_type \n: If the dueling is on, what type of it. The default is average", 
            "title": "Overview"
        }, 
        {
            "location": "/sources/agents/overview/#godqnagent", 
            "text": "core.agent.agents.GODQNAgent()  Class for the Goal-Oriented agents with a DQN-based policy learning.  This class is extending the class AbstractDQNAgent from keras-rl framework.\nThis type of DQN agent should learn the policies of a dialogue in a given environment.  One agent action is represented as a dictionary having the exact same structure as the user action, which is:    diaact  : the act (intent) of the action   inform_slots  : the set of informed slots   request_slots  : the set of request slots   nl  : the natural language representation of the agent action   The following methods are implemented:   forward  backward  compile  load_weights  save_weights  layers   Class members:  From   Agent  class:    processor   ( Processor  instance): glue between the environment and the agent   From   AbstractDQNAgent  class:    nb_actions  : the number of all possible actions   memory   ( Memory  instance): the type of buffer the agent will use. For example: SequentialMemory   gamma  : the discount reward factor. Default is 0.99, the agent remembers everything   batch_size  : the number of memories to replay in one training epoch. Default is 32   nb_steps_warmup  : the number of steps needed to warm up and fill the memory replay buffer. Default is 1000   train_interval  : no idea   memory_interval  : no idea   target_model_update  : after how many steps, the target DQN gets updated. Default is 10 000   delta_range  : no idea. Default is None. This variable is deprecated   delta_clip  : no idea. Default is Inf   custom_model_objects  : no idea   From  DQNAgent  class:    policy   ( Policy  instance): The policy that the agent follows. Default is None   test_policy   ( Policy  instance): The policy that the agent follows during testing. Default is None   enable_double_dqn  : To enable the Double DQN technique. By default is on   enable_dueling_network  : To enble the Dueling DQN technique. Be default is off   dueling_type  : If the dueling is on, what type of it. The default is average", 
            "title": "GODQNAgent"
        }, 
        {
            "location": "/sources/environment/overview/", 
            "text": "[source]\n\n\nGOEnv\n\n\ncore.environment.environment.GOEnv(simulation_mode=None, is_training=False, user_type_str='', user_path='', dst_type_str='', dst_path='', act_set=None, slot_set=None, feasible_actions=None, max_nb_turns=None, nlu_path='', nlg_path='')\n\n\n\n\nThe Environment with which the agent is interacting with. It extends the keras-rl class Env.\nTherefore, the following methods are implemented:\n\n\n\n\nstep\n\n\nreset\n\n\nrender\n\n\nclose\n\n\nseed\n\n\nconfigure\n\n\n\n\nClass members:\n\n\nFrom \nrl.Env\n class:\n\n\n\n\n reward_shape \n: the shape of the reward matrix\n\n\n action_space \n: the space of possible actions\n\n\n observation_space \n: the space of observations to ... (have to find the exact meaning)\n\n\n\n\nOwn:\n\n\n\n\n simulation_mode \n: the mode of the simulation, semantic frame or natural language sentences\n\n\n is_training \n: flag indicating the training/testing mode\n\n\n max_nb_turns \n: the maximal number of allowed dialogue turns. Afterwards, the dialogue is considered failed\n\n\n usr \n: a simulated or real user making a conversation with the agent\n\n\n state_tracker \n: the state tracker used for tracking the state of the dialogue\n\n\n nlu_unit \n: the NLU unit for transforming the user utterance to a dialogue act\n\n\n nlg_unit \n: the NLG unit for transforming the agent's action to a natural language sentence\n\n\n act_set \n: the set of all dialogue acts\n\n\n slot_set \n: the set of all dialogue slots\n\n\n feasible_actions \n: list of templates described as dictionaries, corresponding to each action the agent might take\n        (dict to be specified)\n\n\n reward_success \n: the signaled reward for successful dialogue\n\n\n reward_failure \n: the signaled reward for failed dialogue\n\n\n reward_neutral \n: the signaled reward for ongoing dialogue", 
            "title": "Overview"
        }, 
        {
            "location": "/sources/environment/overview/#goenv", 
            "text": "core.environment.environment.GOEnv(simulation_mode=None, is_training=False, user_type_str='', user_path='', dst_type_str='', dst_path='', act_set=None, slot_set=None, feasible_actions=None, max_nb_turns=None, nlu_path='', nlg_path='')  The Environment with which the agent is interacting with. It extends the keras-rl class Env.\nTherefore, the following methods are implemented:   step  reset  render  close  seed  configure   Class members:  From  rl.Env  class:    reward_shape  : the shape of the reward matrix   action_space  : the space of possible actions   observation_space  : the space of observations to ... (have to find the exact meaning)   Own:    simulation_mode  : the mode of the simulation, semantic frame or natural language sentences   is_training  : flag indicating the training/testing mode   max_nb_turns  : the maximal number of allowed dialogue turns. Afterwards, the dialogue is considered failed   usr  : a simulated or real user making a conversation with the agent   state_tracker  : the state tracker used for tracking the state of the dialogue   nlu_unit  : the NLU unit for transforming the user utterance to a dialogue act   nlg_unit  : the NLG unit for transforming the agent's action to a natural language sentence   act_set  : the set of all dialogue acts   slot_set  : the set of all dialogue slots   feasible_actions  : list of templates described as dictionaries, corresponding to each action the agent might take\n        (dict to be specified)   reward_success  : the signaled reward for successful dialogue   reward_failure  : the signaled reward for failed dialogue   reward_neutral  : the signaled reward for ongoing dialogue", 
            "title": "GOEnv"
        }, 
        {
            "location": "/sources/environment/environment/", 
            "text": "[source]\n\n\nGOEnv\n\n\ncore.environment.environment.GOEnv(simulation_mode=None, is_training=False, user_type_str='', user_path='', dst_type_str='', dst_path='', act_set=None, slot_set=None, feasible_actions=None, max_nb_turns=None, nlu_path='', nlg_path='')\n\n\n\n\nThe Environment with which the agent is interacting with. It extends the keras-rl class Env.\nTherefore, the following methods are implemented:\n\n\n\n\nstep\n\n\nreset\n\n\nrender\n\n\nclose\n\n\nseed\n\n\nconfigure\n\n\n\n\nClass members:\n\n\nFrom \nrl.Env\n class:\n\n\n\n\n reward_shape \n: the shape of the reward matrix\n\n\n action_space \n: the space of possible actions\n\n\n observation_space \n: the space of observations to ... (have to find the exact meaning)\n\n\n\n\nOwn:\n\n\n\n\n simulation_mode \n: the mode of the simulation, semantic frame or natural language sentences\n\n\n is_training \n: flag indicating the training/testing mode\n\n\n max_nb_turns \n: the maximal number of allowed dialogue turns. Afterwards, the dialogue is considered failed\n\n\n usr \n: a simulated or real user making a conversation with the agent\n\n\n state_tracker \n: the state tracker used for tracking the state of the dialogue\n\n\n nlu_unit \n: the NLU unit for transforming the user utterance to a dialogue act\n\n\n nlg_unit \n: the NLG unit for transforming the agent's action to a natural language sentence\n\n\n act_set \n: the set of all dialogue acts\n\n\n slot_set \n: the set of all dialogue slots\n\n\n feasible_actions \n: list of templates described as dictionaries, corresponding to each action the agent might take\n        (dict to be specified)\n\n\n reward_success \n: the signaled reward for successful dialogue\n\n\n reward_failure \n: the signaled reward for failed dialogue\n\n\n reward_neutral \n: the signaled reward for ongoing dialogue\n\n\n\n\n\n\n[source]\n\n\nstep\n\n\nstep(self, action)\n\n\n\n\nMethod for taking the environment one step further. In this case, to present the agent action to the user in order\nto make a response. Overrides the super class method.\n\n\nArguments:\n\n\n\n\n action \n: the last agent action\n\n\n\n\n return \n: user's response to the agent's action in form of a state\n\n\n\n\n[source]\n\n\nreset\n\n\nreset(self)\n\n\n\n\nMethod for resetting the dialogue state tracker and the user, called at the beginning of each new episode.\nOverrides the super class method.\n\n\n:return: the initial observation\n\n\n\n\n[source]\n\n\nclose\n\n\nclose(self)\n\n\n\n\n\n\n[source]\n\n\nseed\n\n\nseed(self, seed=None)\n\n\n\n\n\n\n[source]\n\n\nconfigure\n\n\nconfigure(self)", 
            "title": "GOEnv"
        }, 
        {
            "location": "/sources/environment/environment/#goenv", 
            "text": "core.environment.environment.GOEnv(simulation_mode=None, is_training=False, user_type_str='', user_path='', dst_type_str='', dst_path='', act_set=None, slot_set=None, feasible_actions=None, max_nb_turns=None, nlu_path='', nlg_path='')  The Environment with which the agent is interacting with. It extends the keras-rl class Env.\nTherefore, the following methods are implemented:   step  reset  render  close  seed  configure   Class members:  From  rl.Env  class:    reward_shape  : the shape of the reward matrix   action_space  : the space of possible actions   observation_space  : the space of observations to ... (have to find the exact meaning)   Own:    simulation_mode  : the mode of the simulation, semantic frame or natural language sentences   is_training  : flag indicating the training/testing mode   max_nb_turns  : the maximal number of allowed dialogue turns. Afterwards, the dialogue is considered failed   usr  : a simulated or real user making a conversation with the agent   state_tracker  : the state tracker used for tracking the state of the dialogue   nlu_unit  : the NLU unit for transforming the user utterance to a dialogue act   nlg_unit  : the NLG unit for transforming the agent's action to a natural language sentence   act_set  : the set of all dialogue acts   slot_set  : the set of all dialogue slots   feasible_actions  : list of templates described as dictionaries, corresponding to each action the agent might take\n        (dict to be specified)   reward_success  : the signaled reward for successful dialogue   reward_failure  : the signaled reward for failed dialogue   reward_neutral  : the signaled reward for ongoing dialogue    [source]", 
            "title": "GOEnv"
        }, 
        {
            "location": "/sources/environment/environment/#step", 
            "text": "step(self, action)  Method for taking the environment one step further. In this case, to present the agent action to the user in order\nto make a response. Overrides the super class method.  Arguments:    action  : the last agent action    return  : user's response to the agent's action in form of a state   [source]", 
            "title": "step"
        }, 
        {
            "location": "/sources/environment/environment/#reset", 
            "text": "reset(self)  Method for resetting the dialogue state tracker and the user, called at the beginning of each new episode.\nOverrides the super class method.  :return: the initial observation   [source]", 
            "title": "reset"
        }, 
        {
            "location": "/sources/environment/environment/#close", 
            "text": "close(self)   [source]", 
            "title": "close"
        }, 
        {
            "location": "/sources/environment/environment/#seed", 
            "text": "seed(self, seed=None)   [source]", 
            "title": "seed"
        }, 
        {
            "location": "/sources/environment/environment/#configure", 
            "text": "configure(self)", 
            "title": "configure"
        }, 
        {
            "location": "/sources/dst/overview/", 
            "text": "[source]\n\n\nGOStateTracker\n\n\ncore.dst.state_tracker.GOStateTracker(act_set=None, slot_set=None, max_nb_turns=None)\n\n\n\n\nAbstract Base Class of all state trackers in the Goal-Oriented Dialogue Systems.\n\n\nClass members:\n\n\n\n\n history \n: list of both user and agent actions, such that they are in alternating order\n\n\n act_set \n: the set of all intents used in the dialogue.\n\n\n slot_set \n: the set of all slots used in the dialogue.\n\n\n act_set_cardinality \n: the cardinality of the act set.\n\n\n slot_set_cardinality \n: the cardinality of the slot set.\n\n\n current_slots \n: a dictionary that keeps a running record of which slots are filled \n        (inform slots) and which are requested (request slots)\n\n\n state_dim \n: the dimensionality of the state. It is calculated afterwards.\n\n\n max_nb_turns \n: the maximal number of dialogue turns\n\n\n\n\n\n\n[source]\n\n\nGORuleBasedStateTracker\n\n\ncore.dst.state_tracker.GORuleBasedStateTracker(act_set=None, slot_set=None, max_nb_turns=None)\n\n\n\n\nClass for Rule-Based state tracker in the Goal-Oriented Dialogue Systems.\nExtends the \nGOStateTracker\n class.\n\n\nClass members:\n\n\n\n\n state_dim \n: the dimension of the state\n\n\n\n\n\n\n[source]\n\n\nGOModelBasedStateTracker\n\n\ncore.dst.state_tracker.GOModelBasedStateTracker(act_set=None, slot_set=None, max_nb_turns=None, is_training=None, model_path=None)\n\n\n\n\nClass for Model-Based state tracker in the Goal-Oriented Dialogue Systems.\nExtends the \nGOStateTracker\n class.\n\n\nClass members:\n\n\n\n\n is_training \n: boolean flag indicating the mode of using the model-based state tracker\n\n\n model_path \n: the path to save or load the model", 
            "title": "Overview"
        }, 
        {
            "location": "/sources/dst/overview/#gostatetracker", 
            "text": "core.dst.state_tracker.GOStateTracker(act_set=None, slot_set=None, max_nb_turns=None)  Abstract Base Class of all state trackers in the Goal-Oriented Dialogue Systems.  Class members:    history  : list of both user and agent actions, such that they are in alternating order   act_set  : the set of all intents used in the dialogue.   slot_set  : the set of all slots used in the dialogue.   act_set_cardinality  : the cardinality of the act set.   slot_set_cardinality  : the cardinality of the slot set.   current_slots  : a dictionary that keeps a running record of which slots are filled \n        (inform slots) and which are requested (request slots)   state_dim  : the dimensionality of the state. It is calculated afterwards.   max_nb_turns  : the maximal number of dialogue turns    [source]", 
            "title": "GOStateTracker"
        }, 
        {
            "location": "/sources/dst/overview/#gorulebasedstatetracker", 
            "text": "core.dst.state_tracker.GORuleBasedStateTracker(act_set=None, slot_set=None, max_nb_turns=None)  Class for Rule-Based state tracker in the Goal-Oriented Dialogue Systems.\nExtends the  GOStateTracker  class.  Class members:    state_dim  : the dimension of the state    [source]", 
            "title": "GORuleBasedStateTracker"
        }, 
        {
            "location": "/sources/dst/overview/#gomodelbasedstatetracker", 
            "text": "core.dst.state_tracker.GOModelBasedStateTracker(act_set=None, slot_set=None, max_nb_turns=None, is_training=None, model_path=None)  Class for Model-Based state tracker in the Goal-Oriented Dialogue Systems.\nExtends the  GOStateTracker  class.  Class members:    is_training  : boolean flag indicating the mode of using the model-based state tracker   model_path  : the path to save or load the model", 
            "title": "GOModelBasedStateTracker"
        }, 
        {
            "location": "/sources/user/overview/", 
            "text": "[source]\n\n\nGOUser\n\n\ncore.user.users.GOUser(id=None, simulation_mode=None, goal_set=None)\n\n\n\n\nAbstract Base Class of all type of Goal-Oriented conversational users. The user is taking an action after each turn.\nOne user action is represented as a dictionary having the exact same structure as the agent action, which is:\n\n\n\n\n diaact \n: the act of the action\n\n\n inform_slots \n: the set of informed slots\n\n\n request_slots \n: the set of request slots\n\n\n nl \n: the natural language representation of the agent action\n\n\n\n\nAlso, the user is having a goal to follow, which is also a dictionary with the same structure as the user or agent\naction, with the difference that all information is provided.\n\n\nMoreover, the agent is keeping its own internal state, for its last turn, represented as a dictionary, which is:\n\n\n\n\n diaact \n: the user's dialogue act\n\n\n inform_slots \n: the user's inform slots from its previous turn\n\n\n request_slots \n: the user's request slots from its previous turn\n\n\n history_slots \n: the history of all user's inform slots\n\n\n rest_slots \n: the history of all user's slots\n\n\n\n\nClass members:\n\n\n\n\n id \n: the id of the user\n\n\n current_turn_nb \n: the number of the current dialogue turn\n\n\n state \n: user internal state, keeping record of the past and current actions\n\n\n simulation_mode \n: semantic frame or natural language sentence form of user utterances\n\n\n goal_set \n: the set of goals for the user\n\n\n goal \n: the user goal in the current dialogue turn\n\n\n\n\n\n\n[source]\n\n\nGORealUser\n\n\ncore.user.users.GORealUser(id=None, goal_set=None)\n\n\n\n\nClass connecting a real user, writing on the standard input. Extends the \nGOUser\n class.\n\n\nClass members:\n\n\n\n\n[source]\n\n\nGOSimulatedUser\n\n\ncore.user.users.GOSimulatedUser(id=None, simulation_mode=None, goal_set=None, slot_set=None, act_set=None)\n\n\n\n\nAbstract Base Class for all simulated users in the Goal-Oriented Dialogue Systems.\nExtends the \nGOUser\n class.\n\n\nClass members:\n\n\n\n\n slot_set \n: the set of all slots in the dialogue scenario\n\n\n act_set \n: the set of all acts (intents) in the dialogue scenario\n\n\n\n\n dialog_status \n: the status of the dialogue from the user perspective. The user is deciding whether the\n           dialogue is finished or not. The dialogue status could have the following value:\n\n\n\n\n NO_OUTCOME_YET \n: the dialogue is still ongoing\n\n\n SUCCESS_DIALOG \n: the dialogue was successful, i.e. the user achieved the goal\n\n\n FAILED_DIALOG \n: the dialogue failed, i.e. the user didn't succeed to achieve the goal\n\n\n\n\n\n\n\n\n\n\n[source]\n\n\nGORuleBasedUser\n\n\ncore.user.users.GORuleBasedUser(id=None, simulation_mode=None, goal_set=None, slot_set=None, act_set=None, init_inform_slots=None, ultimate_request_slot=None)\n\n\n\n\nAbstract class representing a rule-based user in the Goal-Oriented Dialogue Systems.\nSince, it is a rule-based simulated user, it will be domain-specific.\nExtends the \nGOUser\n class.\n\n\nClass members:\n\n\n\n\n\n\n init_inform_slots \n: list of initial inform slots, such that if the current user goal is containing some\n               of them, they must appear in the initial user turn\n\n\n\n\n\n\n ultimate_request_slot \n : the slot that is the actual goal of the user, and everything is around this slot.\n\n\n\n\n\n\n\n\n[source]\n\n\nGOModelBasedUser\n\n\ncore.user.users.GOModelBasedUser(id=None, simulation_mode=None, goal_set=None, slot_set=None, act_set=None, is_training=None, model_path=None)\n\n\n\n\nClass representing a model based user in the Goal-Oriented Dialogue Systems.\nExtends the \nGOUser\n class.\n\n\nClass members:\n\n\n\n\n is_training \n: boolean flag indicating the mode of using te model-based state tracker\n\n\n model_path \n: the path to save or load the model", 
            "title": "Overview"
        }, 
        {
            "location": "/sources/user/overview/#gouser", 
            "text": "core.user.users.GOUser(id=None, simulation_mode=None, goal_set=None)  Abstract Base Class of all type of Goal-Oriented conversational users. The user is taking an action after each turn.\nOne user action is represented as a dictionary having the exact same structure as the agent action, which is:    diaact  : the act of the action   inform_slots  : the set of informed slots   request_slots  : the set of request slots   nl  : the natural language representation of the agent action   Also, the user is having a goal to follow, which is also a dictionary with the same structure as the user or agent\naction, with the difference that all information is provided.  Moreover, the agent is keeping its own internal state, for its last turn, represented as a dictionary, which is:    diaact  : the user's dialogue act   inform_slots  : the user's inform slots from its previous turn   request_slots  : the user's request slots from its previous turn   history_slots  : the history of all user's inform slots   rest_slots  : the history of all user's slots   Class members:    id  : the id of the user   current_turn_nb  : the number of the current dialogue turn   state  : user internal state, keeping record of the past and current actions   simulation_mode  : semantic frame or natural language sentence form of user utterances   goal_set  : the set of goals for the user   goal  : the user goal in the current dialogue turn    [source]", 
            "title": "GOUser"
        }, 
        {
            "location": "/sources/user/overview/#gorealuser", 
            "text": "core.user.users.GORealUser(id=None, goal_set=None)  Class connecting a real user, writing on the standard input. Extends the  GOUser  class.  Class members:   [source]", 
            "title": "GORealUser"
        }, 
        {
            "location": "/sources/user/overview/#gosimulateduser", 
            "text": "core.user.users.GOSimulatedUser(id=None, simulation_mode=None, goal_set=None, slot_set=None, act_set=None)  Abstract Base Class for all simulated users in the Goal-Oriented Dialogue Systems.\nExtends the  GOUser  class.  Class members:    slot_set  : the set of all slots in the dialogue scenario   act_set  : the set of all acts (intents) in the dialogue scenario    dialog_status  : the status of the dialogue from the user perspective. The user is deciding whether the\n           dialogue is finished or not. The dialogue status could have the following value:    NO_OUTCOME_YET  : the dialogue is still ongoing   SUCCESS_DIALOG  : the dialogue was successful, i.e. the user achieved the goal   FAILED_DIALOG  : the dialogue failed, i.e. the user didn't succeed to achieve the goal      [source]", 
            "title": "GOSimulatedUser"
        }, 
        {
            "location": "/sources/user/overview/#gorulebaseduser", 
            "text": "core.user.users.GORuleBasedUser(id=None, simulation_mode=None, goal_set=None, slot_set=None, act_set=None, init_inform_slots=None, ultimate_request_slot=None)  Abstract class representing a rule-based user in the Goal-Oriented Dialogue Systems.\nSince, it is a rule-based simulated user, it will be domain-specific.\nExtends the  GOUser  class.  Class members:     init_inform_slots  : list of initial inform slots, such that if the current user goal is containing some\n               of them, they must appear in the initial user turn     ultimate_request_slot   : the slot that is the actual goal of the user, and everything is around this slot.     [source]", 
            "title": "GORuleBasedUser"
        }, 
        {
            "location": "/sources/user/overview/#gomodelbaseduser", 
            "text": "core.user.users.GOModelBasedUser(id=None, simulation_mode=None, goal_set=None, slot_set=None, act_set=None, is_training=None, model_path=None)  Class representing a model based user in the Goal-Oriented Dialogue Systems.\nExtends the  GOUser  class.  Class members:    is_training  : boolean flag indicating the mode of using te model-based state tracker   model_path  : the path to save or load the model", 
            "title": "GOModelBasedUser"
        }
    ]
}